use std::collections::BTreeMap;
use std::time::Duration;

use bytes::{Buf, BufMut, BytesMut};
use tokio::time::{Instant, sleep_until};
use wtransport::{RecvStream, SendStream};

use crate::model::control::fetch::Fetch;
use crate::model::control::subscribe::Subscribe;
use crate::model::data::fetch_header::FetchHeader;
use crate::model::data::fetch_object::FetchObject;
use crate::model::data::object::Object;
use crate::model::data::subgroup_header::SubgroupHeader;
use crate::model::data::subgroup_object::SubgroupObject;
use crate::model::error::ParseError;

const DATA_STREAM_TIMEOUT: Duration = Duration::from_secs(10); // Timeout for header and subsequent objects
const MTU_SIZE: usize = 1500; // Standard MTU size

// Stores the context derived from the initial header message
#[derive(Debug)]
pub enum HeaderInfo {
  Fetch {
    header: FetchHeader,
    fetch_request: Fetch, // Store the original request for context
  },
  Subgroup {
    header: SubgroupHeader,
    subscribe_request: Subscribe, // Store the original request for context
  },
}
/// # Pseudocode
/// ```rust
/// open-uni
/// let head = FetchHeader::new(..)
/// let data_Stream = SendDataStream::new(head, Fetch).await?;
/// loop{
/// //get the object
/// let object = Object{..}
/// data_stream.send_object().await
/// }
///
/// ```
pub struct SendDataStream {
  send_stream: SendStream,
  header_info: HeaderInfo,
}

// TODO: Major issue, can't distinguish from FetchHeader + FetchObject from SubgroupHeader
// Suggestion: SubgroupHeader should start with Request ID and discard track_alias
impl SendDataStream {
  pub async fn new(
    mut send_stream: SendStream,
    header_info: HeaderInfo,
  ) -> Result<Self, ParseError> {
    let mut buf = BytesMut::new();

    match &header_info {
      HeaderInfo::Fetch { header, .. } => {
        buf.extend_from_slice(&header.serialize()?);
      }
      HeaderInfo::Subgroup { header, .. } => {
        buf.extend_from_slice(&header.serialize()?);
      }
    }

    send_stream
      .write_all(&buf)
      .await
      .map_err(|e| ParseError::Other {
        context: "SendDataStream::new(header write)",
        msg: e.to_string(),
      })?;

    Ok(Self {
      send_stream,
      header_info,
    })
  }

  pub async fn send_object(&mut self, object: &Object) -> Result<(), ParseError> {
    let mut buf = BytesMut::new();
    let object = object.clone();

    match &self.header_info {
      HeaderInfo::Fetch { .. } => {
        let fetch_obj = object.try_into_fetch()?;
        buf.extend_from_slice(&fetch_obj.serialize()?);
      }
      HeaderInfo::Subgroup { header, .. } => {
        let has_extensions = header.header_type.has_extensions();
        let subgroup_obj = object.try_into_subgroup()?;
        buf.extend_from_slice(&subgroup_obj.serialize(has_extensions)?);
      }
    }

    self
      .send_stream
      .write_all(&buf)
      .await
      .map_err(|e| ParseError::Other {
        context: "SendDataStream::send_object",
        msg: e.to_string(),
      })?;

    Ok(())
  }
}

/// # Pseudocode
/// ```rust
/// accept-uni
/// let pending_fetch: &mut BTreeMap<u64, Fetch> = Session.fetch_requests;
/// let pending_subscribe: &mut BTreeMap<u64, Subscribe> = Session.subscribe_requests.
/// let data_Stream = RecvDataStream::new(head, ,pending_fetch, pending_subscribe).await?;
/// loop{
/// //get the object
/// let object = data_stream.next_object().await;
/// }
/// ```
pub struct RecvDataStream {
  recv_stream: RecvStream,
  recv_bytes: BytesMut,
  recv_buf: Box<[u8; MTU_SIZE]>,
  header_info: HeaderInfo,
}

impl RecvDataStream {
  pub async fn new(
    mut recv_stream: RecvStream,
    pending_fetch: &mut BTreeMap<u64, Fetch>, // Mutable borrow to potentially remove entry
    pending_subscribe: &mut BTreeMap<u64, Subscribe>, // Mutable borrow
    is_fetch: bool, // Dirty trick to guide the RecvDataStream to guess if incoming header is FetchHeader, false: SubgroupHeader
  ) -> Result<Self, ParseError> {
    let mut recv_bytes = BytesMut::new();
    let mut recv_buf = Box::new([0; MTU_SIZE]);

    loop {
      if !recv_bytes.is_empty() {
        let mut bytes_cursor = recv_bytes.clone().freeze();
        let original_remaining = bytes_cursor.remaining();
        if is_fetch {
          match FetchHeader::deserialize(&mut bytes_cursor) {
            Ok(fetch_header) => {
              if let Some(fetch_request) = pending_fetch.get(&fetch_header.request_id) {
                let consumed = original_remaining - bytes_cursor.remaining();
                recv_bytes.advance(consumed);
                return Ok(Self {
                  recv_stream,
                  recv_bytes,
                  recv_buf,
                  header_info: HeaderInfo::Fetch {
                    header: fetch_header,
                    fetch_request: fetch_request.clone(),
                  },
                });
              } else {
                return Err(ParseError::ProcotolViolation {
                  context: "RecvDataStream::new(FetchHeader validation)",
                  details: format!(
                    "Received FetchHeader for unknown request_id: {}",
                    fetch_header.request_id
                  ),
                });
              }
            }
            Err(ParseError::NotEnoughBytes { .. }) => {}
            Err(e) => {
              return Err(ParseError::ProcotolViolation {
                context: "RecvDataStream::new(FetchHeader validation)",
                details: e.to_string(),
              });
            }
          }
        } else {
          match SubgroupHeader::deserialize(&mut bytes_cursor) {
            Ok(subgroup_header) => {
              if let Some(subscribe_request) = pending_subscribe.get(&subgroup_header.track_alias) {
                // TODO: Check if group_id matches
                let consumed = original_remaining - bytes_cursor.remaining();
                recv_bytes.advance(consumed);
                return Ok(Self {
                  recv_stream,
                  recv_bytes,
                  recv_buf,
                  header_info: HeaderInfo::Subgroup {
                    header: subgroup_header,
                    subscribe_request: subscribe_request.clone(),
                  },
                });
              } else {
                return Err(ParseError::ProcotolViolation {
                  context: "RecvDataStream::new(SubgroupHeader validation)",
                  details: format!(
                    "Received SubgroupHeader for unknown track_alias: {}",
                    subgroup_header.track_alias
                  ),
                });
              }
            }
            Err(ParseError::NotEnoughBytes { .. }) => {}
            Err(e) => {
              return Err(ParseError::ProcotolViolation {
                context: "RecvDataStream::new(SubgroupHeader validation)",
                details: e.to_string(),
              });
            }
          }
        }

        //let mut bytes_cursor = recv_bytes.clone().freeze();
      }

      tokio::select! {
          biased;

          _ = sleep_until(Instant::now() + DATA_STREAM_TIMEOUT) => {
              return Err(ParseError::Timeout { context: "RecvDataStream::new(header_read)" });
          }

          read_result = recv_stream.read(&mut recv_buf[..]) => {
              match read_result {
                  Ok(Some(n)) => {
                      if n > 0 {
                          recv_bytes.put_slice(&recv_buf[..n]);
                      } else {
                          // Spurious read, loop again
                      }
                  }
                  Ok(None) => {
                      return Err(ParseError::Other { context: "RecvDataStream::new(header_read)", msg:"Stream closed before receiving any bytes".to_string() });
                  }
                  Err(e) => {
                      return Err(ParseError::Other { context: "RecvDataStream::new(header_read)", msg:e.to_string() });
                  }
              }
          }
      }
    }
  }

  pub async fn next_object(&mut self) -> Result<Object, ParseError> {
    loop {
      if !self.recv_bytes.is_empty() {
        let mut bytes_cursor = self.recv_bytes.clone().freeze();
        let original_remaining = bytes_cursor.remaining();

        let parse_result = match &self.header_info {
          HeaderInfo::Fetch { .. } => {
            FetchObject::deserialize(&mut bytes_cursor).and_then(|fetch_obj| {
              // TODO: Validation checks fetch objects arriving correctly
              // TODO: Get track alias from fetch_request
              Object::try_from_fetch(fetch_obj, 0)
            })
          }
          HeaderInfo::Subgroup { header, .. } => {
            let has_extensions = header.header_type.has_extensions();
            SubgroupObject::deserialize(&mut bytes_cursor, has_extensions).and_then(
              |subgroup_obj| {
                // TODO: Validation checks

                Object::try_from_subgroup(
                  subgroup_obj,
                  header.track_alias,
                  header.group_id,
                  header.subgroup_id,
                  header.publisher_priority,
                )
              },
            )
          }
        };

        match parse_result {
          Ok(object) => {
            let consumed = original_remaining - bytes_cursor.remaining();
            self.recv_bytes.advance(consumed);
            return Ok(object);
          }
          Err(ParseError::NotEnoughBytes { .. }) => {}
          Err(e) => {
            return Err(ParseError::ProcotolViolation {
              context: "RecvDataStream::next_object(parse_result)",
              details: e.to_string(),
            });
          }
        }
      }

      tokio::select! {
          biased;

          _ = sleep_until(Instant::now() + DATA_STREAM_TIMEOUT) => {
              return Err(ParseError::Timeout { context: "RecvDataStream::next_object(timeout)" });
          }

          read_result = self.recv_stream.read(&mut self.recv_buf[..]) => {
            match read_result {
              Ok(Some(n)) => {
                  if n > 0 {
                      self.recv_bytes.put_slice(&self.recv_buf[..n]);
                  } else {
                    // Spurious read, loop again
                  }
              }
              Ok(None) => {
                if self.recv_bytes.is_empty(){
                  // TODO: Check if we recevied all objects. Return Err(e) if closed prematurely
                }else{
                  return Err(ParseError::Other { context: "RecvDataStream::next_object(object_read)", msg:"Stream closed prematurely".to_string() });
                }
              }
              Err(e) => {
                  return Err(ParseError::Other { context: "RecvDataStream::next_object(object_read)", msg:e.to_string() });
              }
          }
          }
      }
    }
  }
}
#[cfg(test)]
mod tests {
  use super::*;
  use crate::model::common::location::Location;
  use crate::model::common::pair::KeyValuePair;
  use crate::model::common::tuple::Tuple;
  use crate::model::control::constant::{FetchType, FilterType, GroupOrder};
  use crate::model::control::fetch::JoiningFetchProps;
  use crate::model::control::{fetch::Fetch, subscribe::Subscribe};
  use crate::model::data::constant::SubgroupHeaderType;
  use bytes::Bytes;
  use std::error::Error;
  use std::sync::Arc;
  use tokio::sync::Mutex;
  use tokio::time::{Duration, sleep};
  use wtransport::endpoint::IntoConnectOptions;
  use wtransport::{ClientConfig, Connection, Endpoint, Identity, RecvStream, SendStream};

  fn make_fetch_header_and_request() -> (FetchHeader, Fetch) {
    let request_id = 161803;
    let subscriber_priority = 15u8;
    let group_order = GroupOrder::Descending;
    let fetch_type = FetchType::AbsoluteFetch;
    let joining_fetch_props = JoiningFetchProps {
      joining_request_id: 119,
      joining_start: 73,
    };
    let parameters = vec![
      KeyValuePair::try_new_varint(4444, 12321).unwrap(),
      KeyValuePair::try_new_bytes(1, Bytes::from_static(b"fetch me ok")).unwrap(),
    ];
    let fetch = Fetch {
      request_id,
      subscriber_priority,
      group_order,
      fetch_type,
      standalone_fetch_props: None,
      joining_fetch_props: Some(joining_fetch_props),
      parameters,
    };
    (FetchHeader { request_id: 161803 }, fetch)
  }

  fn make_fetch_object() -> FetchObject {
    let group_id: u64 = 9;
    let subgroup_id = 144;
    let object_id: u64 = 10;
    let publisher_priority: u8 = 255;
    let extension_headers = Some(vec![
      KeyValuePair::try_new_varint(0, 10).unwrap(),
      KeyValuePair::try_new_bytes(1, Bytes::from_static(b"wololoo")).unwrap(),
    ]);
    let object_status = None;
    let payload = Some(Bytes::from_static(
      b"01239gjawkk92837aljwdnjwandjnanwdjnajwndkjawndjkanwdkjnawkjddmi",
    ));

    FetchObject {
      group_id,
      subgroup_id,
      object_id,
      publisher_priority,
      extension_headers,
      payload,
      object_status,
    }
  }

  fn make_object_from_fetch(fetch_obj: &FetchObject) -> Object {
    Object::try_from_fetch(fetch_obj.clone(), 0).unwrap()
  }

  fn make_subgroup_header_and_request() -> (SubgroupHeader, Subscribe) {
    let request_id = 128242;
    let track_alias = 999;
    let track_namespace = Tuple::from_utf8_path("nein/nein/nein");
    let track_name = "${Name}".to_string();
    let subscriber_priority = 31;
    let group_order = GroupOrder::Original;
    let forward = true;
    let filter_type = FilterType::AbsoluteRange;
    let start_location = Location {
      group: 81,
      object: 81,
    };
    let end_group = 25;
    let subscribe_parameters = vec![
      KeyValuePair::try_new_varint(0, 10).unwrap(),
      KeyValuePair::try_new_bytes(1, Bytes::from_static(b"I'll sync you up")).unwrap(),
    ];
    let subscribe = Subscribe {
      request_id,
      track_alias,
      track_namespace,
      track_name,
      subscriber_priority,
      group_order,
      forward,
      filter_type,
      start_location: Some(start_location),
      end_group: Some(end_group),
      subscribe_parameters,
    };
    let header_type = SubgroupHeaderType::Type0x0D;
    let track_alias = 999;
    let group_id = 9;
    let subgroup_id = Some(11);
    let publisher_priority = 255;
    let subgroup_header = SubgroupHeader {
      header_type,
      track_alias,
      group_id,
      subgroup_id,
      publisher_priority,
    };
    (subgroup_header, subscribe)
  }

  fn make_subgroup_object() -> SubgroupObject {
    let object_id: u64 = 10;
    let extension_headers = Some(vec![
      KeyValuePair::try_new_varint(0, 10).unwrap(),
      KeyValuePair::try_new_bytes(1, Bytes::from_static(b"wololoo")).unwrap(),
    ]);
    let object_status = None;
    let payload = Some(Bytes::from_static(b"01239gjawkk92837aldmi"));

    SubgroupObject {
      object_id,
      extension_headers,
      payload,
      object_status,
    }
  }

  fn make_object_from_subgroup(subgroup_obj: &SubgroupObject, header: &SubgroupHeader) -> Object {
    Object::try_from_subgroup(
      subgroup_obj.clone(),
      header.track_alias,
      header.group_id,
      header.subgroup_id,
      header.publisher_priority,
    )
    .unwrap()
  }

  struct TestSetup {
    client: Connection,
    server: Connection,
  }

  impl TestSetup {
    async fn new() -> Result<Self, Box<dyn Error>> {
      let server_identity = Identity::self_signed(std::iter::once("localhost"))
        .map_err(|e| format!("Failed to create server identity: {}", e))?;
      let server_cert_hash = server_identity.certificate_chain().as_slice()[0].hash();
      let server_config = wtransport::ServerConfig::builder()
        .with_bind_address(
          "127.0.0.1:0"
            .parse()
            .map_err(|e| format!("Failed to parse bind address: {}", e))?,
        )
        .with_identity(server_identity)
        .build();
      let server_endpoint = Endpoint::server(server_config)
        .map_err(|e| format!("Failed to create server endpoint: {}", e))?;
      let server_addr = server_endpoint
        .local_addr()
        .map_err(|e| format!("Failed to get server local address: {}", e))?;

      // Create a channel to get the server connection from the spawned task
      let (tx, rx) = tokio::sync::oneshot::channel();

      // Spawn a task to handle the server connection acceptance
      tokio::spawn(async move {
        let result = async {
          let incoming = server_endpoint.accept().await;
          let session_request = incoming
            .await
            .map_err(|e| format!("Failed to await session request: {}", e))
            .unwrap();
          let server = session_request.accept().await.unwrap();
          Ok::<_, Box<dyn Error + Send>>(server)
        }
        .await;

        if tx.send(result).is_err() {
          eprintln!("Failed to send server connection result back through the channel");
        }
      });

      // Create client configuration with server's certificate hash for verification
      let client_config = ClientConfig::builder()
        .with_bind_default()
        .with_server_certificate_hashes(vec![server_cert_hash])
        .build();

      let client_endpoint = Endpoint::client(client_config)
        .map_err(|e| format!("Failed to create client endpoint: {}", e))?;

      // Start client connection concurrently while server is accepting
      let client = client_endpoint
        .connect(
          format!("https://{}:{}", server_addr.ip(), server_addr.port())
            .as_str()
            .into_options(),
        )
        .await
        .map_err(|e| format!("Client connection failed: {}", e))?;

      // Wait for the server connection from the spawned task
      let server = rx
        .await
        .map_err(|_| "Server task failed to send connection back")?
        .map_err(|e| format!("Server connection error: {}", e))?;

      Ok(Self { client, server })
    }

    async fn create_data_stream_pair(&self) -> Result<(SendStream, RecvStream), Box<dyn Error>> {
      // Client opens a unidirectional stream (SendStream) in a spawned task
      let client = self.client.clone();
      let send_fut = tokio::spawn(async move {
        // The first await returns Result<SendUni, StreamOpeningError>
        // The second await returns Result<SendStream, StreamOpeningError>
        let send_uni = client.open_uni().await.unwrap();
        send_uni.await
      });

      // Server accepts the unidirectional stream (RecvStream) in a spawned task
      let server = self.server.clone();
      let recv_fut = tokio::spawn(async move {
        server
          .accept_uni()
          .await
          .map_err(|e| format!("Failed to accept server uni stream: {}", e))
      });

      // Await both concurrently
      let (send_res, recv_res) = tokio::try_join!(send_fut, recv_fut)?;

      let send = send_res.map_err(|e| format!("Failed to open client uni stream: {}", e))?;
      let recv = recv_res.map_err(|e| format!("Failed to accept server uni stream: {}", e))?;

      Ok((send, recv))
    }
  }

  async fn setup_stream_pair() -> (SendStream, RecvStream) {
    let setup = TestSetup::new()
      .await
      .expect("Failed to setup test transport");
    setup
      .create_data_stream_pair()
      .await
      .expect("Failed to create data stream pair")
  }

  #[tokio::test]
  async fn test_send_recv_fetch_object_success() {
    let (send, recv) = setup_stream_pair().await;
    let (fetch_header, fetch_req) = make_fetch_header_and_request();
    let mut pending_fetch = BTreeMap::new();
    pending_fetch.insert(fetch_req.request_id, fetch_req.clone());
    let mut pending_subscribe = BTreeMap::new();

    // Sender
    let mut sender = SendDataStream::new(
      send,
      HeaderInfo::Fetch {
        header: fetch_header.clone(),
        fetch_request: fetch_req.clone(),
      },
    )
    .await
    .unwrap();

    let fetch_obj = make_fetch_object();
    let object = make_object_from_fetch(&fetch_obj);

    // Receiver
    let mut receiver = RecvDataStream::new(recv, &mut pending_fetch, &mut pending_subscribe, true)
      .await
      .unwrap();

    sender.send_object(&object).await.unwrap();
    let received = receiver.next_object().await.unwrap();

    assert_eq!(object, received);
  }

  #[tokio::test]
  async fn test_send_recv_subgroup_object_success() {
    let (send, recv) = setup_stream_pair().await;
    let (subgroup_header, subscribe_req) = make_subgroup_header_and_request();
    let mut pending_fetch = BTreeMap::new();
    let mut pending_subscribe = BTreeMap::new();
    pending_subscribe.insert(subscribe_req.track_alias, subscribe_req.clone());

    let mut sender = SendDataStream::new(
      send,
      HeaderInfo::Subgroup {
        header: subgroup_header.clone(),
        subscribe_request: subscribe_req.clone(),
      },
    )
    .await
    .unwrap();

    let subgroup_obj = make_subgroup_object();
    let object = make_object_from_subgroup(&subgroup_obj, &subgroup_header);

    let mut receiver = RecvDataStream::new(recv, &mut pending_fetch, &mut pending_subscribe, false)
      .await
      .unwrap();

    sender.send_object(&object).await.unwrap();
    let received = receiver.next_object().await.unwrap();

    assert_eq!(object, received);
  }

  #[tokio::test]
  async fn test_timeout_on_header() {
    let (_send, recv) = setup_stream_pair().await;
    let mut pending_fetch = BTreeMap::new();
    let mut pending_subscribe = BTreeMap::new();

    // Don't send any header, just wait for timeout
    let result = RecvDataStream::new(recv, &mut pending_fetch, &mut pending_subscribe, true).await;

    match result {
      Err(ParseError::Timeout { .. }) => {}
      _ => panic!("Should timeout"),
    }
  }

  #[tokio::test]
  async fn test_partial_object_timeout() {
    let (send, recv) = setup_stream_pair().await;
    let (fetch_header, fetch_req) = make_fetch_header_and_request();
    let mut pending_fetch = BTreeMap::new();
    pending_fetch.insert(fetch_req.request_id, fetch_req.clone());
    let mut pending_subscribe = BTreeMap::new();

    // Send only the header, not the object
    let mut _sender = SendDataStream::new(
      send,
      HeaderInfo::Fetch {
        header: fetch_header.clone(),
        fetch_request: fetch_req.clone(),
      },
    )
    .await
    .unwrap();

    let mut receiver = RecvDataStream::new(recv, &mut pending_fetch, &mut pending_subscribe, true)
      .await
      .unwrap();

    // Don't send any object, just wait for timeout
    let result = receiver.next_object().await;
    match result {
      Err(ParseError::Timeout { .. }) => {}
      other => panic!("Expected timeout, got {:?}", other),
    }
  }

  #[tokio::test]
  async fn test_partial_object_completion() {
    let (send, recv) = setup_stream_pair().await;
    let (fetch_header, fetch_req) = make_fetch_header_and_request();
    let mut pending_fetch = BTreeMap::new();
    pending_fetch.insert(fetch_req.request_id, fetch_req.clone());
    let mut pending_subscribe = BTreeMap::new();

    let mut sender = SendDataStream::new(
      send,
      HeaderInfo::Fetch {
        header: fetch_header.clone(),
        fetch_request: fetch_req.clone(),
      },
    )
    .await
    .unwrap();

    let fetch_obj = make_fetch_object();
    let object = make_object_from_fetch(&fetch_obj);

    let mut receiver = RecvDataStream::new(recv, &mut pending_fetch, &mut pending_subscribe, true)
      .await
      .unwrap();

    // Serialize object and send in two parts
    let bytes = fetch_obj.serialize().unwrap();
    let half = bytes.len() / 2;
    let first_half = &bytes[..half];
    let second_half = &bytes[half..];

    // Send first half
    sender.send_stream.write_all(first_half).await.unwrap();

    // Spawn a task to send the second half after a delay
    let send_stream = Arc::new(Mutex::new(sender.send_stream));
    let second_half = second_half.to_vec();
    tokio::spawn({
      let send_stream = Arc::clone(&send_stream);
      async move {
        sleep(Duration::from_millis(100)).await;
        let mut s = send_stream.lock().await;
        s.write_all(&second_half).await.unwrap();
      }
    });

    let received = receiver.next_object().await.unwrap();
    assert_eq!(object, received);
  }
}
